{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:37:27.828302Z",
     "start_time": "2025-02-01T19:37:24.044464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator"
   ],
   "id": "5175b93817895455",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:37:28.042455Z",
     "start_time": "2025-02-01T19:37:27.828302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translator = GoogleTranslator(source='en', target='ro')\n",
    "\n",
    "to_translate = \"The bigger a child's shoe size, the better the child's handwriting\"\n",
    "translated = translator.translate(to_translate)\n",
    "translated"
   ],
   "id": "64e2b3c4dd7b2bc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cu cât mărimea pantofilor unui copil este mai mare, cu atât scrisul de mână al copilului este mai bun'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:37:31.267759Z",
     "start_time": "2025-02-01T19:37:31.257657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translator = GoogleTranslator(source='en', target='ro')\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        translated = translator.translate(text)\n",
    "        return translated\n",
    "    except Exception as e:\n",
    "        print(f\"Translation failed: {e}\")\n",
    "        return text"
   ],
   "id": "6b72bd5e9318dc3c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Translating huggingface LOGIC dataset",
   "id": "40093b6938f643b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T16:52:14.548153Z",
     "start_time": "2024-10-05T16:52:07.840567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "full_data = load_dataset(\"tasksource/logical-fallacy\")"
   ],
   "id": "df916eec91588e53",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T16:52:25.932177Z",
     "start_time": "2024-10-05T16:52:25.911165Z"
    }
   },
   "cell_type": "code",
   "source": "full_data['test'].shape",
   "id": "b894c85cffc4793a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T16:55:57.454879Z",
     "start_time": "2024-10-05T16:55:57.423548Z"
    }
   },
   "cell_type": "code",
   "source": "full_data['dev'].shape",
   "id": "3403591c22c6c875",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:24:39.457170Z",
     "start_time": "2024-09-30T08:15:47.634863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = pd.DataFrame(full_data['test'])\n",
    "test['source_article_ro'] = test['source_article'].apply(translate_text)\n",
    "test.to_csv('test.csv', index=False)"
   ],
   "id": "dad01e49c53f804e",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:11:16.157176Z",
     "start_time": "2024-09-30T08:27:05.805913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.DataFrame(full_data['train'])\n",
    "train['source_article_ro'] = train['source_article'].apply(translate_text)\n",
    "train.to_csv('data/huggingface/train.csv', index=False)"
   ],
   "id": "4194eedd0e44f0f5",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:20:13.425085Z",
     "start_time": "2024-09-30T09:11:52.877581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev = pd.DataFrame(full_data['dev'])\n",
    "dev['source_article_ro'] = dev['source_article'].apply(translate_text)\n",
    "dev.to_csv('data/huggingface/dev.csv', index=False)"
   ],
   "id": "b7dfc8616cab33f9",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Translating LFUD dataset",
   "id": "6ba679a9eeca2299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:38:29.034778Z",
     "start_time": "2024-09-30T09:38:28.987342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lfud = pd.read_csv(\"data/LFUD.csv\")\n",
    "lfud.head()"
   ],
   "id": "4c59ee8f499fa36e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   index                                proposition  \\\n",
       "0      0  All electronic products need electricity.   \n",
       "1      1  All electronic products need electricity.   \n",
       "2      2  All electronic products need electricity.   \n",
       "3      3  All electronic products need electricity.   \n",
       "4      4  All electronic products need electricity.   \n",
       "\n",
       "                                            sentence           fallacy_type  \\\n",
       "0  All electronic products need electricity. Elec...  faulty generalization   \n",
       "1  Since all electronic products need electricity...        false causality   \n",
       "2  All electronic products function because they ...     circular reasoning   \n",
       "3  Most people think that all electronic products...             ad populum   \n",
       "4  \"Either every electronic item operates using e...          false dilemma   \n",
       "\n",
       "                                               task1  \\\n",
       "0  {'question': 'Statement: All electronic produc...   \n",
       "1  {'question': 'Statement: Since all electronic ...   \n",
       "2  {'question': 'Statement: All electronic produc...   \n",
       "3  {'question': 'Statement: Most people think tha...   \n",
       "4  {'question': 'Statement: \"Either every electro...   \n",
       "\n",
       "                                               task2  \\\n",
       "0  {'question': 'Faulty generalization occurs whe...   \n",
       "1  {'question': 'False causality occurs when an a...   \n",
       "2  {'question': 'Circular reasoning occurs when a...   \n",
       "3  {'question': 'Ad populum occurs when an argume...   \n",
       "4  {'question': 'False dilemma occurs when incorr...   \n",
       "\n",
       "                                               task3  \\\n",
       "0  {'question': 'Faulty generalization occurs whe...   \n",
       "1  {'question': 'False causality occurs when an a...   \n",
       "2  {'question': 'Circular reasoning occurs when a...   \n",
       "3  {'question': 'Ad populum occurs when an argume...   \n",
       "4  {'question': 'False dilemma occurs when incorr...   \n",
       "\n",
       "                                               task4  \\\n",
       "0  {'question': 'Faulty generalization occurs whe...   \n",
       "1  {'question': 'False causality occurs when an a...   \n",
       "2  {'question': 'Circular reasoning occurs when a...   \n",
       "3  {'question': 'Ad populum occurs when an argume...   \n",
       "4  {'question': 'False dilemma occurs when incorr...   \n",
       "\n",
       "                                               task5  \n",
       "0  {'question': 'Original sentence: All electroni...  \n",
       "1  {'question': 'Original sentence: Since all ele...  \n",
       "2  {'question': 'Original sentence: All electroni...  \n",
       "3  {'question': 'Original sentence: Most people t...  \n",
       "4  {'question': 'Original sentence: \"Either every...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>proposition</th>\n",
       "      <th>sentence</th>\n",
       "      <th>fallacy_type</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>task3</th>\n",
       "      <th>task4</th>\n",
       "      <th>task5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>All electronic products need electricity. Elec...</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>{'question': 'Statement: All electronic produc...</td>\n",
       "      <td>{'question': 'Faulty generalization occurs whe...</td>\n",
       "      <td>{'question': 'Faulty generalization occurs whe...</td>\n",
       "      <td>{'question': 'Faulty generalization occurs whe...</td>\n",
       "      <td>{'question': 'Original sentence: All electroni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>Since all electronic products need electricity...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>{'question': 'Statement: Since all electronic ...</td>\n",
       "      <td>{'question': 'False causality occurs when an a...</td>\n",
       "      <td>{'question': 'False causality occurs when an a...</td>\n",
       "      <td>{'question': 'False causality occurs when an a...</td>\n",
       "      <td>{'question': 'Original sentence: Since all ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>All electronic products function because they ...</td>\n",
       "      <td>circular reasoning</td>\n",
       "      <td>{'question': 'Statement: All electronic produc...</td>\n",
       "      <td>{'question': 'Circular reasoning occurs when a...</td>\n",
       "      <td>{'question': 'Circular reasoning occurs when a...</td>\n",
       "      <td>{'question': 'Circular reasoning occurs when a...</td>\n",
       "      <td>{'question': 'Original sentence: All electroni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>Most people think that all electronic products...</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>{'question': 'Statement: Most people think tha...</td>\n",
       "      <td>{'question': 'Ad populum occurs when an argume...</td>\n",
       "      <td>{'question': 'Ad populum occurs when an argume...</td>\n",
       "      <td>{'question': 'Ad populum occurs when an argume...</td>\n",
       "      <td>{'question': 'Original sentence: Most people t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>\"Either every electronic item operates using e...</td>\n",
       "      <td>false dilemma</td>\n",
       "      <td>{'question': 'Statement: \"Either every electro...</td>\n",
       "      <td>{'question': 'False dilemma occurs when incorr...</td>\n",
       "      <td>{'question': 'False dilemma occurs when incorr...</td>\n",
       "      <td>{'question': 'False dilemma occurs when incorr...</td>\n",
       "      <td>{'question': 'Original sentence: \"Either every...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:38:54.278327Z",
     "start_time": "2024-09-30T09:38:54.262309Z"
    }
   },
   "cell_type": "code",
   "source": "lfud.drop(['task1', 'task2', 'task3', 'task4', 'task5'], axis=1, inplace=True)",
   "id": "c1e6ef27a18c2a11",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:58:53.931239Z",
     "start_time": "2024-09-30T09:42:46.070406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lfud['proposition_ro'] = lfud['proposition'].apply(translate_text)\n",
    "lfud['sentence_ro'] = lfud['sentence'].apply(translate_text)\n",
    "lfud.to_csv('data/logical_fallacy_understanding_dataset/lfud.csv', index=False)"
   ],
   "id": "bbc1f9b3f34e61d0",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Translating Nonfallacies ",
   "id": "a97b8173965f97ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T08:23:55.840950Z",
     "start_time": "2025-02-02T08:23:54.243940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "f3e2db1f07cd2722",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:37:46.527124Z",
     "start_time": "2025-02-01T19:37:41.413238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"data/facts/AllCombined.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "cleaned_text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "cleaned_text = re.sub(r\"(?m)^[A-Za-z]{1,15}\\s*$\\n?\", \"\\n\", cleaned_text)"
   ],
   "id": "986d420b128248",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:37:48.198157Z",
     "start_time": "2025-02-01T19:37:47.425107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_file_path = \"data/facts/cleaned_facts.txt\"\n",
    "with open(cleaned_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(cleaned_text)"
   ],
   "id": "1984d9879df72320",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extracting the first n phrases",
   "id": "9bb441e72b5a4c3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:37:55.904897Z",
     "start_time": "2025-02-01T19:37:54.177517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_first_n_phrases(file_path, n=1):\n",
    "    sentences = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        paragraphs = text.split(\"\\n\\n\")\n",
    "        for paragraph in paragraphs:\n",
    "            phrases = paragraph.split(\"\\n\")\n",
    "            for phrase in phrases[:n]:\n",
    "                sentence = phrase.split(\". \")\n",
    "                if len(sentence) > 5:\n",
    "                    sentences.append(sentence[0])\n",
    "        return sentences\n",
    "\n",
    "first_two_phrases = extract_first_n_phrases(cleaned_file_path, 1)\n",
    "print(len(first_two_phrases))\n",
    "print(first_two_phrases[:10])"
   ],
   "id": "f1b1669a82b68a73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3687\n",
      "[\"Air is the Earth's atmosphere\", 'An abbreviation is a shorter way to write a word or phrase', 'Algebra (from Arabic: الجبر\\u200e, transliterated \"al-jabr\", meaning \"reunion of broken parts\") is a part of mathematics', 'An atom is an extremely small piece of matter', 'Angola, officially the Republic of Angola, is a country in southern Africa', 'A boot is a type of footwear that protects the foot and ankle', 'A computer is a machine that uses electronics to input, process, store, and output data', 'To chat is to talk about ordinary things that are not usually very important', 'Comedy (from ), in modern times, is an entertainment with generally funny content', 'A comet is a ball of mostly ice that moves around in outer space']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:38:06.373577Z",
     "start_time": "2025-02-01T19:38:06.212613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/all/combined_lfud_huggingface.csv')\n",
    "df.shape"
   ],
   "id": "67518dcddcc06277",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4565, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:39:17.345865Z",
     "start_time": "2025-02-01T19:39:17.325587Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "d47d7a88a1742895",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      source_article     logical_fallacies  \\\n",
       "0          company's slogan \"Expect More. Pay Less.\"     appeal to emotion   \n",
       "1  The bigger a child's shoe size, the better the...       false causality   \n",
       "2  Since many people believe this, then it must b...            ad populum   \n",
       "3  Senator Randall isn't lying when she says she ...    circular reasoning   \n",
       "4  A mother is telling her daughter that she went...  fallacy of relevance   \n",
       "\n",
       "                                   source_article_ro proposition  \\\n",
       "0  sloganul companiei „Așteptați mai mult. Plătiț...         NaN   \n",
       "1  Cu cât mărimea pantofilor unui copil este mai ...         NaN   \n",
       "2  Din moment ce mulți oameni cred asta, atunci t...         NaN   \n",
       "3  Senatorul Randall nu minte când spune că îi pa...         NaN   \n",
       "4  O mamă îi spune fiicei ei că și-a analizat dat...         NaN   \n",
       "\n",
       "  proposition_ro  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_article</th>\n",
       "      <th>logical_fallacies</th>\n",
       "      <th>source_article_ro</th>\n",
       "      <th>proposition</th>\n",
       "      <th>proposition_ro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company's slogan \"Expect More. Pay Less.\"</td>\n",
       "      <td>appeal to emotion</td>\n",
       "      <td>sloganul companiei „Așteptați mai mult. Plătiț...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The bigger a child's shoe size, the better the...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>Cu cât mărimea pantofilor unui copil este mai ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since many people believe this, then it must b...</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>Din moment ce mulți oameni cred asta, atunci t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senator Randall isn't lying when she says she ...</td>\n",
       "      <td>circular reasoning</td>\n",
       "      <td>Senatorul Randall nu minte când spune că îi pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A mother is telling her daughter that she went...</td>\n",
       "      <td>fallacy of relevance</td>\n",
       "      <td>O mamă îi spune fiicei ei că și-a analizat dat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:39:28.725604Z",
     "start_time": "2025-02-01T19:39:28.715392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_two_phrases = first_two_phrases[:len(df)//4]\n",
    "nonfallacies_df = pd.DataFrame({\n",
    "    'source_article': first_two_phrases,\n",
    "    'logical_fallacies': ['nonfallacy'] * len(first_two_phrases)\n",
    "})"
   ],
   "id": "84db5ce6c40433ff",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:39:29.811508Z",
     "start_time": "2025-02-01T19:39:29.801496Z"
    }
   },
   "cell_type": "code",
   "source": "print(nonfallacies_df.shape)",
   "id": "d2ab126e95fa47aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1141, 2)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T19:39:36.242003Z",
     "start_time": "2025-02-01T19:39:36.222041Z"
    }
   },
   "cell_type": "code",
   "source": "nonfallacies_df.head()",
   "id": "6d8c8dcd50254483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      source_article logical_fallacies\n",
       "0                      Air is the Earth's atmosphere        nonfallacy\n",
       "1  An abbreviation is a shorter way to write a wo...        nonfallacy\n",
       "2  Algebra (from Arabic: الجبر‎, transliterated \"...        nonfallacy\n",
       "3      An atom is an extremely small piece of matter        nonfallacy\n",
       "4  Angola, officially the Republic of Angola, is ...        nonfallacy"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_article</th>\n",
       "      <th>logical_fallacies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air is the Earth's atmosphere</td>\n",
       "      <td>nonfallacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An abbreviation is a shorter way to write a wo...</td>\n",
       "      <td>nonfallacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algebra (from Arabic: الجبر‎, transliterated \"...</td>\n",
       "      <td>nonfallacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An atom is an extremely small piece of matter</td>\n",
       "      <td>nonfallacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola, officially the Republic of Angola, is ...</td>\n",
       "      <td>nonfallacy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-01T19:39:39.296845Z"
    }
   },
   "cell_type": "code",
   "source": "nonfallacies_df['source_article_ro'] = nonfallacies_df['source_article'].apply(translate_text)",
   "id": "bb40e8a7e1459ef1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ],
   "id": "6e720b1255f46167",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nonfallacies_df['proposition'] = np.nan\n",
    "nonfallacies_df['proposition_ro'] = np.nan"
   ],
   "id": "1713563034878c92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nonfallacies_df.head(10)",
   "id": "96eb30889004b94d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_df = pd.concat([df, nonfallacies_df], ignore_index=True)\n",
    "combined_df"
   ],
   "id": "e7a2496e2e107ced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T08:26:53.581612Z",
     "start_time": "2025-02-02T08:26:48.637181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils import shuffle\n",
    "shuffled_df = shuffle(combined_df, random_state=42)\n",
    "shuffled_df"
   ],
   "id": "46e33bb063d4ef83",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         source_article  \\\n",
       "2273  Such misrepresentations are now commonplace in...   \n",
       "1094  If we use just one more can of hairspray this ...   \n",
       "3095  That doesn ’ t mean pollution controls are fut...   \n",
       "2986                         The Earth is not warming .   \n",
       "3254     McDonald's Hamburgers: over 99 billion served.   \n",
       "...                                                 ...   \n",
       "3772  If a gadget qualifies as an electronic product...   \n",
       "5191                 Poole is a town in Dorset, England   \n",
       "5226                         A lock keeps things closed   \n",
       "5390  Curium is a synthetic chemical element in the ...   \n",
       "860   Speaker 1: We are using thousands of people, w...   \n",
       "\n",
       "          logical_fallacies  \\\n",
       "2273            intentional   \n",
       "1094  faulty generalization   \n",
       "3095   fallacy of relevance   \n",
       "2986            intentional   \n",
       "3254             ad populum   \n",
       "...                     ...   \n",
       "3772      deductive fallacy   \n",
       "5191             nonfallacy   \n",
       "5226             nonfallacy   \n",
       "5390             nonfallacy   \n",
       "860            equivocation   \n",
       "\n",
       "                                      source_article_ro  \\\n",
       "2273  Astfel de denaturari sunt acum obisnuite in an...   \n",
       "1094  Dacă mai folosim o singură cutie de fixativ lu...   \n",
       "3095  Asta nu înseamnă că controalele poluării sunt ...   \n",
       "2986                         Pământul nu se încălzește.   \n",
       "3254  Hamburgeri McDonald's: peste 99 de miliarde se...   \n",
       "...                                                 ...   \n",
       "3772  Dacă un gadget se califică drept produs electr...   \n",
       "5191              Poole este un oraș din Dorset, Anglia   \n",
       "5226                    Un lacăt ține lucrurile închise   \n",
       "5390  Curiul este un element chimic sintetic din tab...   \n",
       "860   Vorbitor 1: Folosim mii de oameni, care merg d...   \n",
       "\n",
       "                                    proposition  \\\n",
       "2273                                        NaN   \n",
       "1094                                        NaN   \n",
       "3095                                        NaN   \n",
       "2986                                        NaN   \n",
       "3254                                        NaN   \n",
       "...                                         ...   \n",
       "3772  All electronic products need electricity.   \n",
       "5191                                        NaN   \n",
       "5226                                        NaN   \n",
       "5390                                        NaN   \n",
       "860                                         NaN   \n",
       "\n",
       "                                         proposition_ro  \n",
       "2273                                                NaN  \n",
       "1094                                                NaN  \n",
       "3095                                                NaN  \n",
       "2986                                                NaN  \n",
       "3254                                                NaN  \n",
       "...                                                 ...  \n",
       "3772  Toate produsele electronice au nevoie de elect...  \n",
       "5191                                                NaN  \n",
       "5226                                                NaN  \n",
       "5390                                                NaN  \n",
       "860                                                 NaN  \n",
       "\n",
       "[5706 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_article</th>\n",
       "      <th>logical_fallacies</th>\n",
       "      <th>source_article_ro</th>\n",
       "      <th>proposition</th>\n",
       "      <th>proposition_ro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>Such misrepresentations are now commonplace in...</td>\n",
       "      <td>intentional</td>\n",
       "      <td>Astfel de denaturari sunt acum obisnuite in an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>If we use just one more can of hairspray this ...</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>Dacă mai folosim o singură cutie de fixativ lu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>That doesn ’ t mean pollution controls are fut...</td>\n",
       "      <td>fallacy of relevance</td>\n",
       "      <td>Asta nu înseamnă că controalele poluării sunt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>The Earth is not warming .</td>\n",
       "      <td>intentional</td>\n",
       "      <td>Pământul nu se încălzește.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>McDonald's Hamburgers: over 99 billion served.</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>Hamburgeri McDonald's: peste 99 de miliarde se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>If a gadget qualifies as an electronic product...</td>\n",
       "      <td>deductive fallacy</td>\n",
       "      <td>Dacă un gadget se califică drept produs electr...</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>Toate produsele electronice au nevoie de elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Poole is a town in Dorset, England</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Poole este un oraș din Dorset, Anglia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>A lock keeps things closed</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Un lacăt ține lucrurile închise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Curium is a synthetic chemical element in the ...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Curiul este un element chimic sintetic din tab...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Speaker 1: We are using thousands of people, w...</td>\n",
       "      <td>equivocation</td>\n",
       "      <td>Vorbitor 1: Folosim mii de oameni, care merg d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5706 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T08:27:00.709326Z",
     "start_time": "2025-02-02T08:27:00.649133Z"
    }
   },
   "cell_type": "code",
   "source": "shuffled_df.to_csv('data/all/combined_lfud_huggingface_nonfallacies.csv', index=False)",
   "id": "404ab8e2c0c1d4eb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T08:27:05.745966Z",
     "start_time": "2025-02-02T08:27:05.735934Z"
    }
   },
   "cell_type": "code",
   "source": "shuffled_df.shape",
   "id": "f7961d64facaff04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5706, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
