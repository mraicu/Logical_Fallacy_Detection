{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:24:48.326384Z",
     "start_time": "2025-01-24T10:24:48.021023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator"
   ],
   "id": "5175b93817895455",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:24:49.768190Z",
     "start_time": "2025-01-24T10:24:49.142875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translator = GoogleTranslator(source='en', target='ro')\n",
    "\n",
    "to_translate = \"The bigger a child's shoe size, the better the child's handwriting\"\n",
    "translated = translator.translate(to_translate)\n",
    "translated"
   ],
   "id": "64e2b3c4dd7b2bc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cu cât dimensiunea pantofilor unui copil este mai mare, cu atât scrisul de mână al copilului este mai bun'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:24:54.166104Z",
     "start_time": "2025-01-24T10:24:54.134474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translator = GoogleTranslator(source='en', target='ro')\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        translated = translator.translate(text)\n",
    "        return translated\n",
    "    except Exception as e:\n",
    "        print(f\"Translation failed: {e}\")\n",
    "        return text"
   ],
   "id": "6b72bd5e9318dc3c",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Translating huggingface LOGIC dataset",
   "id": "40093b6938f643b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T16:52:14.548153Z",
     "start_time": "2024-10-05T16:52:07.840567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "full_data = load_dataset(\"tasksource/logical-fallacy\")"
   ],
   "id": "df916eec91588e53",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T16:52:25.932177Z",
     "start_time": "2024-10-05T16:52:25.911165Z"
    }
   },
   "cell_type": "code",
   "source": "full_data['test'].shape",
   "id": "b894c85cffc4793a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T16:55:57.454879Z",
     "start_time": "2024-10-05T16:55:57.423548Z"
    }
   },
   "cell_type": "code",
   "source": "full_data['dev'].shape",
   "id": "3403591c22c6c875",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:24:39.457170Z",
     "start_time": "2024-09-30T08:15:47.634863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = pd.DataFrame(full_data['test'])\n",
    "test['source_article_ro'] = test['source_article'].apply(translate_text)\n",
    "test.to_csv('test.csv', index=False)"
   ],
   "id": "dad01e49c53f804e",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:11:16.157176Z",
     "start_time": "2024-09-30T08:27:05.805913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.DataFrame(full_data['train'])\n",
    "train['source_article_ro'] = train['source_article'].apply(translate_text)\n",
    "train.to_csv('data/huggingface/train.csv', index=False)"
   ],
   "id": "4194eedd0e44f0f5",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:20:13.425085Z",
     "start_time": "2024-09-30T09:11:52.877581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev = pd.DataFrame(full_data['dev'])\n",
    "dev['source_article_ro'] = dev['source_article'].apply(translate_text)\n",
    "dev.to_csv('data/huggingface/dev.csv', index=False)"
   ],
   "id": "b7dfc8616cab33f9",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Translating LFUD dataset",
   "id": "6ba679a9eeca2299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:38:29.034778Z",
     "start_time": "2024-09-30T09:38:28.987342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lfud = pd.read_csv(\"data/LFUD.csv\")\n",
    "lfud.head()"
   ],
   "id": "4c59ee8f499fa36e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   index                                proposition  \\\n",
       "0      0  All electronic products need electricity.   \n",
       "1      1  All electronic products need electricity.   \n",
       "2      2  All electronic products need electricity.   \n",
       "3      3  All electronic products need electricity.   \n",
       "4      4  All electronic products need electricity.   \n",
       "\n",
       "                                            sentence           fallacy_type  \\\n",
       "0  All electronic products need electricity. Elec...  faulty generalization   \n",
       "1  Since all electronic products need electricity...        false causality   \n",
       "2  All electronic products function because they ...     circular reasoning   \n",
       "3  Most people think that all electronic products...             ad populum   \n",
       "4  \"Either every electronic item operates using e...          false dilemma   \n",
       "\n",
       "                                               task1  \\\n",
       "0  {'question': 'Statement: All electronic produc...   \n",
       "1  {'question': 'Statement: Since all electronic ...   \n",
       "2  {'question': 'Statement: All electronic produc...   \n",
       "3  {'question': 'Statement: Most people think tha...   \n",
       "4  {'question': 'Statement: \"Either every electro...   \n",
       "\n",
       "                                               task2  \\\n",
       "0  {'question': 'Faulty generalization occurs whe...   \n",
       "1  {'question': 'False causality occurs when an a...   \n",
       "2  {'question': 'Circular reasoning occurs when a...   \n",
       "3  {'question': 'Ad populum occurs when an argume...   \n",
       "4  {'question': 'False dilemma occurs when incorr...   \n",
       "\n",
       "                                               task3  \\\n",
       "0  {'question': 'Faulty generalization occurs whe...   \n",
       "1  {'question': 'False causality occurs when an a...   \n",
       "2  {'question': 'Circular reasoning occurs when a...   \n",
       "3  {'question': 'Ad populum occurs when an argume...   \n",
       "4  {'question': 'False dilemma occurs when incorr...   \n",
       "\n",
       "                                               task4  \\\n",
       "0  {'question': 'Faulty generalization occurs whe...   \n",
       "1  {'question': 'False causality occurs when an a...   \n",
       "2  {'question': 'Circular reasoning occurs when a...   \n",
       "3  {'question': 'Ad populum occurs when an argume...   \n",
       "4  {'question': 'False dilemma occurs when incorr...   \n",
       "\n",
       "                                               task5  \n",
       "0  {'question': 'Original sentence: All electroni...  \n",
       "1  {'question': 'Original sentence: Since all ele...  \n",
       "2  {'question': 'Original sentence: All electroni...  \n",
       "3  {'question': 'Original sentence: Most people t...  \n",
       "4  {'question': 'Original sentence: \"Either every...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>proposition</th>\n",
       "      <th>sentence</th>\n",
       "      <th>fallacy_type</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>task3</th>\n",
       "      <th>task4</th>\n",
       "      <th>task5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>All electronic products need electricity. Elec...</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>{'question': 'Statement: All electronic produc...</td>\n",
       "      <td>{'question': 'Faulty generalization occurs whe...</td>\n",
       "      <td>{'question': 'Faulty generalization occurs whe...</td>\n",
       "      <td>{'question': 'Faulty generalization occurs whe...</td>\n",
       "      <td>{'question': 'Original sentence: All electroni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>Since all electronic products need electricity...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>{'question': 'Statement: Since all electronic ...</td>\n",
       "      <td>{'question': 'False causality occurs when an a...</td>\n",
       "      <td>{'question': 'False causality occurs when an a...</td>\n",
       "      <td>{'question': 'False causality occurs when an a...</td>\n",
       "      <td>{'question': 'Original sentence: Since all ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>All electronic products function because they ...</td>\n",
       "      <td>circular reasoning</td>\n",
       "      <td>{'question': 'Statement: All electronic produc...</td>\n",
       "      <td>{'question': 'Circular reasoning occurs when a...</td>\n",
       "      <td>{'question': 'Circular reasoning occurs when a...</td>\n",
       "      <td>{'question': 'Circular reasoning occurs when a...</td>\n",
       "      <td>{'question': 'Original sentence: All electroni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>Most people think that all electronic products...</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>{'question': 'Statement: Most people think tha...</td>\n",
       "      <td>{'question': 'Ad populum occurs when an argume...</td>\n",
       "      <td>{'question': 'Ad populum occurs when an argume...</td>\n",
       "      <td>{'question': 'Ad populum occurs when an argume...</td>\n",
       "      <td>{'question': 'Original sentence: Most people t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>All electronic products need electricity.</td>\n",
       "      <td>\"Either every electronic item operates using e...</td>\n",
       "      <td>false dilemma</td>\n",
       "      <td>{'question': 'Statement: \"Either every electro...</td>\n",
       "      <td>{'question': 'False dilemma occurs when incorr...</td>\n",
       "      <td>{'question': 'False dilemma occurs when incorr...</td>\n",
       "      <td>{'question': 'False dilemma occurs when incorr...</td>\n",
       "      <td>{'question': 'Original sentence: \"Either every...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:38:54.278327Z",
     "start_time": "2024-09-30T09:38:54.262309Z"
    }
   },
   "cell_type": "code",
   "source": "lfud.drop(['task1', 'task2', 'task3', 'task4', 'task5'], axis=1, inplace=True)",
   "id": "c1e6ef27a18c2a11",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:58:53.931239Z",
     "start_time": "2024-09-30T09:42:46.070406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lfud['proposition_ro'] = lfud['proposition'].apply(translate_text)\n",
    "lfud['sentence_ro'] = lfud['sentence'].apply(translate_text)\n",
    "lfud.to_csv('data/logical_fallacy_understanding_dataset/lfud.csv', index=False)"
   ],
   "id": "bbc1f9b3f34e61d0",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Translating Nonfallacies ",
   "id": "a97b8173965f97ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:10:56.506236Z",
     "start_time": "2025-01-24T11:10:56.484219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "f3e2db1f07cd2722",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T08:28:26.433290Z",
     "start_time": "2025-01-22T08:28:21.456249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"data/facts/AllCombined.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "cleaned_text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "cleaned_text = re.sub(r\"(?m)^[A-Za-z]{1,15}\\s*$\\n?\", \"\\n\", cleaned_text)"
   ],
   "id": "986d420b128248",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T08:28:46.992996Z",
     "start_time": "2025-01-22T08:28:46.225458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_file_path = \"file-name.txt\"\n",
    "with open(cleaned_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(cleaned_text)"
   ],
   "id": "1984d9879df72320",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extracting the first n phrases",
   "id": "9bb441e72b5a4c3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:29:07.220798Z",
     "start_time": "2025-01-24T10:29:05.282946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_first_n_phrases(file_path, n=1):\n",
    "    sentences = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        paragraphs = text.split(\"\\n\\n\")\n",
    "        for paragraph in paragraphs:\n",
    "            phrases = paragraph.split(\"\\n\")\n",
    "            for phrase in phrases[:n]:\n",
    "                sentence = phrase.split(\". \")\n",
    "                if len(sentence) > 5:\n",
    "                    sentences.append(sentence[0])\n",
    "        return sentences\n",
    "\n",
    "first_two_phrases = extract_first_n_phrases(\"cleaned_data.txt\", 1)\n",
    "print(len(first_two_phrases))\n",
    "print(first_two_phrases[:10])"
   ],
   "id": "f1b1669a82b68a73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3687\n",
      "[\"Air is the Earth's atmosphere\", 'An abbreviation is a shorter way to write a word or phrase', 'Algebra (from Arabic: الجبر\\u200e, transliterated \"al-jabr\", meaning \"reunion of broken parts\") is a part of mathematics', 'An atom is an extremely small piece of matter', 'Angola, officially the Republic of Angola, is a country in southern Africa', 'A boot is a type of footwear that protects the foot and ankle', 'A computer is a machine that uses electronics to input, process, store, and output data', 'To chat is to talk about ordinary things that are not usually very important', 'Comedy (from ), in modern times, is an entertainment with generally funny content', 'A comet is a ball of mostly ice that moves around in outer space']\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:29:07.268194Z",
     "start_time": "2025-01-24T10:29:07.220798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/all/combined_lfud_huggingface.csv')\n",
    "df.shape"
   ],
   "id": "67518dcddcc06277",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4565, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:13:27.335386Z",
     "start_time": "2025-01-24T11:13:27.303697Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "d47d7a88a1742895",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      source_article     logical_fallacies  \\\n",
       "0          company's slogan \"Expect More. Pay Less.\"     appeal to emotion   \n",
       "1  The bigger a child's shoe size, the better the...       false causality   \n",
       "2  Since many people believe this, then it must b...            ad populum   \n",
       "3  Senator Randall isn't lying when she says she ...    circular reasoning   \n",
       "4  A mother is telling her daughter that she went...  fallacy of relevance   \n",
       "\n",
       "                                   source_article_ro proposition  \\\n",
       "0  sloganul companiei „Așteptați mai mult. Plătiț...         NaN   \n",
       "1  Cu cât mărimea pantofilor unui copil este mai ...         NaN   \n",
       "2  Din moment ce mulți oameni cred asta, atunci t...         NaN   \n",
       "3  Senatorul Randall nu minte când spune că îi pa...         NaN   \n",
       "4  O mamă îi spune fiicei ei că și-a analizat dat...         NaN   \n",
       "\n",
       "  proposition_ro  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_article</th>\n",
       "      <th>logical_fallacies</th>\n",
       "      <th>source_article_ro</th>\n",
       "      <th>proposition</th>\n",
       "      <th>proposition_ro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company's slogan \"Expect More. Pay Less.\"</td>\n",
       "      <td>appeal to emotion</td>\n",
       "      <td>sloganul companiei „Așteptați mai mult. Plătiț...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The bigger a child's shoe size, the better the...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>Cu cât mărimea pantofilor unui copil este mai ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since many people believe this, then it must b...</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>Din moment ce mulți oameni cred asta, atunci t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senator Randall isn't lying when she says she ...</td>\n",
       "      <td>circular reasoning</td>\n",
       "      <td>Senatorul Randall nu minte când spune că îi pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A mother is telling her daughter that she went...</td>\n",
       "      <td>fallacy of relevance</td>\n",
       "      <td>O mamă îi spune fiicei ei că și-a analizat dat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:29:07.299418Z",
     "start_time": "2025-01-24T10:29:07.283797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_two_phrases = first_two_phrases[:len(df)//2]\n",
    "nonfallacies_df = pd.DataFrame({\n",
    "    'source_article': first_two_phrases,\n",
    "    'logical_fallacies': ['nonfallacy'] * len(first_two_phrases)\n",
    "})"
   ],
   "id": "84db5ce6c40433ff",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:29:09.440642Z",
     "start_time": "2025-01-24T10:29:09.424962Z"
    }
   },
   "cell_type": "code",
   "source": "print(nonfallacies_df.shape)",
   "id": "d2ab126e95fa47aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2282, 2)\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:10:36.769086Z",
     "start_time": "2025-01-24T10:29:11.933281Z"
    }
   },
   "cell_type": "code",
   "source": "nonfallacies_df['source_article_ro'] = nonfallacies_df['source_article'].apply(translate_text)",
   "id": "bb40e8a7e1459ef1",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:10:37.984828Z",
     "start_time": "2025-01-24T11:10:36.942183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ],
   "id": "6e720b1255f46167",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:11:00.580342Z",
     "start_time": "2025-01-24T11:11:00.549083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nonfallacies_df['proposition'] = np.nan\n",
    "nonfallacies_df['proposition_ro'] = np.nan"
   ],
   "id": "1713563034878c92",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:11:02.384570Z",
     "start_time": "2025-01-24T11:11:02.372624Z"
    }
   },
   "cell_type": "code",
   "source": "nonfallacies_df.head(10)",
   "id": "96eb30889004b94d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      source_article logical_fallacies  \\\n",
       "0                      Air is the Earth's atmosphere        nonfallacy   \n",
       "1  An abbreviation is a shorter way to write a wo...        nonfallacy   \n",
       "2  Algebra (from Arabic: الجبر‎, transliterated \"...        nonfallacy   \n",
       "3      An atom is an extremely small piece of matter        nonfallacy   \n",
       "4  Angola, officially the Republic of Angola, is ...        nonfallacy   \n",
       "5  A boot is a type of footwear that protects the...        nonfallacy   \n",
       "6  A computer is a machine that uses electronics ...        nonfallacy   \n",
       "7  To chat is to talk about ordinary things that ...        nonfallacy   \n",
       "8  Comedy (from ), in modern times, is an enterta...        nonfallacy   \n",
       "9  A comet is a ball of mostly ice that moves aro...        nonfallacy   \n",
       "\n",
       "                                   source_article_ro  proposition  \\\n",
       "0                    Aerul este atmosfera Pământului          NaN   \n",
       "1  O abreviere este o modalitate mai scurtă de a ...          NaN   \n",
       "2  Algebra (din arabă: الجبر, transliterat „al-ja...          NaN   \n",
       "3    Un atom este o bucată de materie extrem de mică          NaN   \n",
       "4  Angola, oficial Republica Angola, este o țară ...          NaN   \n",
       "5  Cizma este un tip de încălțăminte care proteje...          NaN   \n",
       "6  Un computer este o mașină care utilizează elec...          NaN   \n",
       "7  A discuta înseamnă a vorbi despre lucruri obiș...          NaN   \n",
       "8  Comedia (din ), în timpurile moderne, este un ...          NaN   \n",
       "9  O cometă este o minge de gheață care se mișcă ...          NaN   \n",
       "\n",
       "   proposition_ro  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "5             NaN  \n",
       "6             NaN  \n",
       "7             NaN  \n",
       "8             NaN  \n",
       "9             NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_article</th>\n",
       "      <th>logical_fallacies</th>\n",
       "      <th>source_article_ro</th>\n",
       "      <th>proposition</th>\n",
       "      <th>proposition_ro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air is the Earth's atmosphere</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Aerul este atmosfera Pământului</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An abbreviation is a shorter way to write a wo...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>O abreviere este o modalitate mai scurtă de a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algebra (from Arabic: الجبر‎, transliterated \"...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Algebra (din arabă: الجبر, transliterat „al-ja...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An atom is an extremely small piece of matter</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Un atom este o bucată de materie extrem de mică</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola, officially the Republic of Angola, is ...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Angola, oficial Republica Angola, este o țară ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A boot is a type of footwear that protects the...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Cizma este un tip de încălțăminte care proteje...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A computer is a machine that uses electronics ...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Un computer este o mașină care utilizează elec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>To chat is to talk about ordinary things that ...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>A discuta înseamnă a vorbi despre lucruri obiș...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Comedy (from ), in modern times, is an enterta...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>Comedia (din ), în timpurile moderne, este un ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A comet is a ball of mostly ice that moves aro...</td>\n",
       "      <td>nonfallacy</td>\n",
       "      <td>O cometă este o minge de gheață care se mișcă ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:11:21.532153Z",
     "start_time": "2025-01-24T11:11:21.516503Z"
    }
   },
   "cell_type": "code",
   "source": "combined_df = pd.concat([df, nonfallacies_df], ignore_index=True)",
   "id": "e7a2496e2e107ced",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:11:22.889664Z",
     "start_time": "2025-01-24T11:11:22.815759Z"
    }
   },
   "cell_type": "code",
   "source": "combined_df.to_csv('data/all/combined_lfud_huggingface_nonfallacies.csv', index=False)",
   "id": "404ab8e2c0c1d4eb",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T11:12:08.142849Z",
     "start_time": "2025-01-24T11:12:08.126782Z"
    }
   },
   "cell_type": "code",
   "source": "combined_df.shape",
   "id": "f7961d64facaff04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6847, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
